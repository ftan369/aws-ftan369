{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The packages needed for this project of prediting flight delays\n",
    "#from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pyspark.sql as sparksql\n",
    "import findspark\n",
    "from matplotlib import pyplot as plt\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is read the data from csv and create a data frame\n",
    "df = spark.read.csv('DelayedFlight.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This show the top 5 rows in the data set (just to see the type of data if its numerical or txt value)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the data type in the dataset\n",
    "df.printSchema()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This show the number of rows in the dataset (raw data)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe Operation using here is use to calculate the summary of all numerical columns in the data frame,hence the ext code was choose only few to explore the data set \n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To show the summary statistics of target attribute is \"ArrDelay\" and other variables correlated attributes.\n",
    "df.describe('ArrDelay', 'DepDelay', 'CarrierDelay', 'LateAircraftDelay', 'NASDelay', 'WeatherDelay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the target variables rows that contains values (NotNull)\n",
    "df.filter(df.ArrDelay.isNull()).count() \n",
    "df.filter(df.ArrDelay.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows the number of missing value in the target variable \"ArrDelay\" \n",
    "df.filter((df['ArrDelay'] == '') | df ['ArrDelay'].isNull() | isnan (df['ArrDelay'])) .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code shows the summary of all the missing values in each field\n",
    "from pyspark.sql.functions import lit\n",
    "rows = df.count() \n",
    "summary = df.describe().filter(col(\"summary\") == \"count\") \n",
    "summary.select(*((lit(rows)-col(c)).alias(c) for c in df.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is show the name of the fields or columns in the dataset (raw data)\n",
    "len(df.columns), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is show the total number of columns in the dataset\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collection of the target variables\n",
    "df.corr('ArrDelay','DepDelay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting delay_col and assign to the target variables\n",
    "delay_col= df.select('ArrDelay')\n",
    "delay_col.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adding another columns in the data set and show only 5 rows\n",
    "df.withColumn('Delay_times_5',df['ArrDelay']*5).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the dataframe and new output missing the new column\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using filter within the dataframe\n",
    "df.filter(\"ArrDelay < 15\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrival delay more than 15 minutes and selction from the carrier and flight number \n",
    "#also how long the departure delay since the arrival flight delay\n",
    "df.filter(\"ArrDelay > 15\").select('DepDelay','FlightNum', 'UniqueCarrier').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample of the advance filter - values between 5 and 10 minutes delay\n",
    "df.filter('ArrDelay <= 5' and 'ArrDelay >=10')\\\n",
    "  .select('FlightNum','DepDelay').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('UniqueCarrier').mean().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify things, let's split this into two steps. First, let's create a variable then order by age.\n",
    "# Careful when using show()! Otherwise the variable type will change and you won't be able to order it. \n",
    "group_UniqueCarrier_df = df.groupBy('UniqueCarrier').mean()\n",
    "\n",
    "# Note that we have to use 'avg(age)' instead of age. Why? Because when you use mean(), it changes the feature's name (as you can see below).\n",
    "print(\"Sorted by ArrDelay\")\n",
    "group_UniqueCarrier_df.orderBy('avg(ArrDelay)').show()\n",
    "\n",
    "# Let's see what this looks like in one line.\n",
    "print(\"Sorted by DepDelay\")\n",
    "df.groupBy('UniqueCarrier').mean().orderBy('avg(DepDelay)').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_UniqueCarrier_df = df.groupBy('ArrDelay').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sorted by UniqueCarrier\")\n",
    "group_UniqueCarrier_df.orderBy('avg(ArrDelay)').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sorted by UniqueCarrier\")\n",
    "df.groupBy('UniqueCarrier').mean().orderBy('avg(DepDelay)').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=\"ArrDelay\")\n",
    "df.show()\n",
    "print(\"Total data points:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find mean average\n",
    "from pyspark.sql.functions import mean\n",
    "mean_ArrDelay = df.select(mean('ArrDelay')).show()\n",
    "mean_ArrDelay= df.select(mean('ArrDelay')).collect()\n",
    "print(mean_ArrDelay)\n",
    "mean_ArrDelay = mean_ArrDelay[0]\n",
    "print(mean_ArrDelay)\n",
    "mean_ArrDelay= mean_ArrDelay[0]\n",
    "print(mean_ArrDelay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing value using mean average\n",
    "df = df.na.fill(mean_ArrDelay, subset=['ArrDelay'])\n",
    "df=df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.na.drop().show()\n",
    "\n",
    "# Let's see how many rows of data we have now. \n",
    "print(\"Total data points:\", df.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
